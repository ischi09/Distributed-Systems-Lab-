{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(raw_results: pd.DataFrame, tasks: List[str], models: List[str]) -> None:\n",
    "    ### Filtering ###\n",
    "    results = raw_results.copy()\n",
    "    results = results[results[\"type\"].isin(models)]\n",
    "    results = results[results[\"label\"].isin(tasks)]\n",
    "\n",
    "    results = results[[\"type\", \"label\", \"test_mae\", \"random_seed\"]]\n",
    "\n",
    "    results = results.rename(\n",
    "        columns={\n",
    "            \"type\": \"model\",\n",
    "            \"label\": \"task\",\n",
    "            \"test_mae\": \"mae\",\n",
    "            \"random_seed\": \"seed\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ### Accumulation ###\n",
    "\n",
    "    mean_results = results.groupby([\"model\", \"task\"], as_index=False).mean()\n",
    "    mean_results.drop(\"seed\", axis=\"columns\", inplace=True)\n",
    "\n",
    "    ### Display ###\n",
    "\n",
    "    # display(mean_results.head(20))\n",
    "\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data=mean_results,\n",
    "        kind=\"bar\",\n",
    "        x=\"task\",\n",
    "        y=\"mae\",\n",
    "        hue=\"model\",\n",
    "        height=10\n",
    "    )\n",
    "    g.set_axis_labels(\"Task\", \"Mean Absolute Error\")\n",
    "    g.set_xticklabels(rotation=30)\n",
    "    g.legend.set_title(\"\")\n",
    "    g._legend.remove()\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "placeholder_results_filename = os.path.join(os.pardir, \"accumulated-set-size-sweeps\", \"regression-entropy.csv\")\n",
    "results = pd.read_csv(placeholder_results_filename)\n",
    "\n",
    "def load_regression_results() -> pd.DataFrame:\n",
    "    part_1_results = pd.read_csv(\"../accumulated-set-size-sweeps/regression-no-entropy.csv\")\n",
    "    part_2_results = pd.read_csv(\"../accumulated-set-size-sweeps/regression-entropy.csv\")\n",
    "    part_2_results = part_2_results.drop(\n",
    "        [\"train_label_entropy\", \"valid_label_entropy\", \"test_label_entropy\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return pd.concat([part_1_results, part_2_results])\n",
    "\n",
    "plot_results(\n",
    "    load_regression_results(),\n",
    "    tasks=[\"sum\", \"largest_pair_sum\", \"largest_triple_sum\", \"max\", \"cardinality\", \"longest_seq_length\", \"largest_contiguous_sum\"],\n",
    "    models=[\"deepsets_mlp_sum\", \"deepsets_mlp_fspool\", \"sorted_mlp\", \"pna\", \"small_set_transformer\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "177a25f46b2a453fd6973cf7dd4d1adbbdfd8ead9f9cd3d26e79d28ca3cb0d75"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('set-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
